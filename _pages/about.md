---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello!

I am a final-year Ph.D. student in the [School of Engineering and Applied Sciences (SEAS) at Harvard University](https://seas.harvard.edu/), affliated with the Natural Langauge Processing (NLP) group in [Harvard](https://nlp.seas.harvard.edu/)/[Cornell](https://rush-nlp.com/members/). I am fortunate to be advised by Professor [Alexander (Sasha) Rush](https://rush-nlp.com/), who is currently at Cornell University.
I also obtained an M.A. degree in Statistics from Harvard University.
Prior to Harvard, I received my B.S. degree in EE from Tsinghua University.

My primary research interests lie in the area of natural language processing and machine learning. I use deep learning and structured prediction methods for understanding language semantics in order to build intelligent systems that are more accurate, interpretable, efficient, and accessible.
Practically, this involves a wide-range of generation problems, such as text, semantic representations, code and programs, reasoning and explanations, etc. with different resources.
I am also broadly interested in learning and generation of structured data (such as graphs) related to/beyond language, and would love to collaborate on data-driven interdisciplinary applications.

Selected Publications
------
<!---
<u>**Enmao Diao**, Ganghua Wang (Equal Contribution)</u>, Jie Ding, Tao Zhang. "Pruning Deep Neural Networks from a Sparsity Perspective."
[\[PDF\]]()
[\[Code\]]()
<span style="color:purple">\[Compression\]</span>
<span style="color:orange">\[Theory\]</span>


**Enmao Diao**, Eric Tramel, Jie Ding, Tao Zhang. "Semi-Supervised Federated Learning for Keyword Spotting."
[\[PDF\]]()
[\[Code\]]()
<span style="color:green">\[Signal Processing\]</span>
<span style="color:coral">\[Semi-Supervised Learning\]</span>
<span style="color:blue">\[Distributed Machine Learning\]</span>


**Enmao Diao**, Vahid Tarokh, Jie Ding. "Privacy-Preserving Multi-Target Multi-Domain Recommender Systems with Assisted
AutoEncoders."
[\[PDF\]](https://arxiv.org/abs/2110.13340)
[\[Code\]]()
<span style="color:brown">\[Recommender Systems\]</span>
<span style="color:blue">\[Distributed Machine Learning\]</span>
-->

<!---
**Enmao Diao**, Jie Ding, Vahid Tarokh. "SemiFL: Communication Efficient Semi-Supervised Federated Learning with
Unlabeled Clients." <i>NeurIPS 2022</i>.
[\[PDF\]](https://arxiv.org/abs/2106.01432)
[\[Code\]]()
<span style="color:coral">\[Semi-Supervised Learning\]</span>
<span style="color:blue">\[Distributed Machine Learning\]</span>
**(Acceptance Rate 25.6%)**

**Enmao Diao**, Jie Ding, Vahid Tarokh. "GAL: Gradient Assisted Learning for Decentralized Multi-Organization
Collaborations." <i>NeurIPS 2022</i>.
[\[PDF\]](https://arxiv.org/abs/2106.01425)
[\[Code\]]()
<span style="color:blue">\[Distributed Machine Learning\]</span>
**(Acceptance Rate 25.6%)**

Suya Wu, **Enmao Diao**, Jie Ding, Vahid Tarokh. "Score-based Hypothesis Testing for Unnormalized Models." <i>IEEE
Access</i>.
[\[PDF\]](https://ieeexplore.ieee.org/document/9813688)
[\[Code\]](https://github.com/suuyawu/Score-based-Hypothesis-Testing-for-Unnormalized-Models)
<span style="color:orange"> \[Theory\]</span>

**Enmao Diao**, Jie Ding, Vahid Tarokh. "Multimodal Controller for Generative Models." <i>CVMI 2022</i>.
[\[PDF\]](https://arxiv.org/abs/2002.02572)
[\[Code\]](https://github.com/dem123456789/Multimodal-Controller-for-Generative-Models)
<span style="color:red">\[Computer Vision\]</span>

Mohammadreza Momenifar, **Enmao Diao**, Vahid Tarokh, Andrew D. Bragg. "Dimension Reduced Turbulent Flow Data From Deep
Vector Quantizers." <i>Journal of Turbulence</i>.
[\[PDF\]](https://arxiv.org/abs/2103.01074)
[\[Code\]](https://github.com/dem123456789/Dimension-Reduced-Turbulent-Flow-Data-From-Deep-Vector-Quantizers)
<span style="color:purple">\[Compression\]</span>
<span style="color:cyan">\[Physics with AI\]</span>

Mohammadreza Momenifar, **Enmao Diao**, Vahid Tarokh, Andrew D. Bragg. "A Physics-Informed Vector Quantized Autoencoder
for Data Compression of Turbulent Flow." <i>DCC 2022</i>.
[\[PDF\]](https://arxiv.org/abs/2201.03617)
[\[Code\]](https://github.com/dem123456789/Dimension-Reduced-Turbulent-Flow-Data-From-Deep-Vector-Quantizers)
<span style="color:purple">\[Compression\]</span>
<span style="color:cyan">\[Physics with AI\]</span>

Mohammadreza Momenifar, **Enmao Diao**, Vahid Tarokh, Andrew D. Bragg. "Emulating Spatio-Temporal Realizations of
Three-Dimensional Isotropic Turbulence via Deep Sequence Learning Models." <i>AAAI 2022 Workshop</i>.
[\[PDF\]](https://arxiv.org/abs/2112.03469)
[\[Code\]](https://github.com/MReza89/Emulating-Spatio-Temporal-Realizations-of-Three-Dimensional-Isotropic-Turbulence-via-Deep-Sequence)
<span style="color:cyan">\[Physics with AI\]</span>

**Enmao Diao**, Jie Ding, Vahid Tarokh. "HeteroFL: Computation and communication efficient federated learning for
heterogeneous clients." <i>ICLR 2021</i>.
[\[PDF\]](https://arxiv.org/abs/2010.01264)
[\[Code\]](https://github.com/dem123456789/HeteroFL)
<span style="color:blue">\[Distributed Machine Learning\]</span>
**(Acceptance Rate 28.7%)**

Jie Ding, **Enmao Diao**, Jiawei Zhou, Vahid Tarokh. "On Statistical Efficiency in Learning." <i>IEEE Transactions on
Information Theory</i>.
[\[PDF\]](https://arxiv.org/abs/2012.13307)
[\[Code\]](https://github.com/dem123456789/On-Statistical-Efficiency-in-Learning)
<span style="color:orange">\[Theory\]</span>

Jianyou Wang, Michael Xue, Ryan Culhane, **Enmao Diao**, Jie Ding, Vahid Tarokh. "Speech emotion recognition with
dual-sequence LSTM architecture." <i>ICASSP 2020</i>.
[\[PDF\]](https://arxiv.org/abs/1910.08874)
[\[Code\]](https://github.com/dem123456789/Speech-Emotion-Recognition-with-Dual-Sequence-LSTM-Architecture)
<span style="color:green">\[Signal Processing\]

**Enmao Diao**, Jie Ding, Vahid Tarokh. "DRASIC: Distributed Recurrent Autoencoder for Scalable Image Compression." <i>
DCC 2020</i>.
[\[PDF\]](https://arxiv.org/abs/1903.09887)
[\[Code\]](https://github.com/dem123456789/Distributed-Recurrent-Autoencoder-for-Scalable-Image-Compression)
<span style="color:purple">\[Compression\]</span>
<span style="color:blue">\[Distributed Machine Learning\]</span>

Suya Wu, **Enmao Diao**, Jie Ding, Vahid Tarokh. "Deep Clustering of Compressed Variational Embeddings." <i>DCC 2020</i>
.
[\[PDF\]](https://arxiv.org/abs/1910.10341)
[\[Code\]](https://github.com/dem123456789/Deep-Clustering-of-Compressed-Variational-Embeddings)
<span style="color:purple">\[Compression\]</span>

**Enmao Diao**, Jie Ding, Vahid Tarokh. "Restricted recurrent neural networks." <i>IEEE BigData 2019</i>.
[\[PDF\]](https://arxiv.org/abs/1908.07724)
[\[Code\]](https://github.com/dem123456789/Restricted-Recurrent-Neural-Networks)
<span style="color:pink">\[Natural Language Processing\]</span>
<span style="color:purple"> \[Compression\]</span>
**(Acceptance Rate 18.7%)**
-->


[Online Semantic Parsing for Latency Reduction in Task-Oriented Dialogue](https://aclanthology.org/2022.acl-long.110/) \
Jiawei Zhou, Jason Eisner, Sam Thomson, Michael Newman, Emmanouil Antonios Platanios \
ACL 2022: the 60th Annual Meeting of the Association for Computational Linguistics
<span style="color:red">\[Outstanding Paper Award\]</span> \
[\[Code\]](https://github.com/microsoft/online-semantic-parsing-for-latency-reduction)
<!-- [\[PDF\]](https://aclanthology.org/2022.acl-long.110/) -->
<!-- Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1554–1576, Dublin, Ireland. 2022. -->

[Structure-aware Fine-tuning of Sequence-to-sequence Transformers for Transition-based AMR Parsing](https://aclanthology.org/2021.emnlp-main.507/) \
Jiawei Zhou, Tahira Naseem, Ramón Fernandez Astudillo, Young-Suk Lee, Radu Florian, and Salim Roukos \
EMNLP 2021: the 2021 Conference on Empirical Methods in Natural Language Processing \
[\[Code\]](https://github.com/IBM/transition-amr-parser)

[AMR Parsing with Action-Pointer Transformer](https://aclanthology.org/2021.naacl-main.443/) \
Jiawei Zhou, Tahira Naseem, RF Astudillo, and Radu Florian \
NAACL 2021: the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies \
[\[Code\]](https://github.com/IBM/transition-amr-parser/tree/action-pointer)

[Improving Non-autoregressive Neural Machine Translation with Monolingual Data](https://aclanthology.org/2020.acl-main.171/) \
Jiawei Zhou, and Phillip Keung \
ACL 2020: the 58th Annual Meeting of the Association for Computational Linguistics \
[\[Code\]](https://github.com/jzhou316/nar-mt-mono)

[Automating Botnet Detection with Graph Neural Networks](https://arxiv.org/pdf/2003.06344.pdf) \
Jiawei Zhou, Zhiying Xu, Alexander M. Rush, Minlan Yu \
MLSys 2020 workshop: AutoML for Networking and Systems Workshop of MLSys 2020 Conference \
[\[Code\]](https://github.com/harvardnlp/botnet-detection)

<!-- [On Statistical Efficiency in Learning](https://arxiv.org/abs/2012.13307) \
Jie Ding, Enmao Diao, Jiawei Zhou, Vahid Tarokh \
TIT: IEEE Transactions on Information Theory, 2020 \
[\[Code\]](https://github.com/dem123456789/On-Statistical-Efficiency-in-Learning) -->

[Simple Unsupervised Summarization by Contextual Matching](https://aclanthology.org/P19-1503/) \
Jiawei Zhou, and Alexander M. Rush \
ACL 2019: the 57th Annual Meeting of the Association for Computational Linguistics \
[\[Code\]](https://github.com/jzhou316/Unsupervised-Sentence-Summarization)

[Asymptotically optimal prediction for time-varying data generating processes](https://people.duke.edu/~vt45/kinetic.pdf) \
Jie Ding, Jiawei Zhou, and Vahid Tarokh \
TIT: IEEE Transactions on Information Theory, 2018
<!-- [\[PDF\]](https://ieeexplore.ieee.org/document/8543249) -->

<!-- Dynamic zero-point attracting projection for time-varying sparse signal recovery \
Jiawei Zhou, Laming Chen, and Yuantao Gu \
ICASSP 2015: the 40th IEEE International Conference on Acoustics, Speech and Signal Processing -->

Full list on [Google Scholar](https://scholar.google.com/citations?user=jJNjxd8AAAAJ&hl=en)

<!-- Jie Ding, **Enmao Diao**, Jiawei Zhou, Vahid Tarokh. "A Penalized Method for the Predictive Limit of Learning." <i>
ICASSP 2018</i>.
[\[PDF\]](https://ieeexplore.ieee.org/document/8461832)
[\[Code\]](https://github.com/dem123456789/On-Statistical-Efficiency-in-Learning)
<span style="color:orange"> \[Theory\]</span> -->

Softwares
------

Botnet detecion with graph neural networks (cybersecurity application) \
[\[Library\]](https://github.com/harvardnlp/botnet-detection)
[\[Published Data\]](https://zenodo.org/record/3689089#.Y5iV7-zMI8Y)

AMR Parsing with neural transition-based approaches (state-of-the-art) \
[\[Library\]](https://github.com/IBM/transition-amr-parser)
<!-- [\[Data\]](https://amr.isi.edu/) -->

Dataflow graph (executable programs) generation for task-oriented dialogue \
[\[Library\]](https://github.com/microsoft/online-semantic-parsing-for-latency-reduction#offline-parsing-train-a-programgraph-prediction-model)
<!-- [\[Data\]](https://github.com/microsoft/task_oriented_dialogue_as_dataflow_synthesis/tree/master/datasets) -->

Unsupervised text summarization \
[\[Code\]](https://github.com/jzhou316/Unsupervised-Sentence-Summarization)

<!-- JPEG decoding -->

<!---
* <a href="https://arxiv.org/abs/2210.00720" style="text-decoration:none">**Complexity-Based Prompting for Multi-Step Reasoning.**</a>
<a href="https://franxyao.github.io/" style="text-decoration:none">Yao Fu</a>, 
Hao Peng, 
<a href="https://allenai.org/team/ashishs" style="text-decoration:none">Ashish Sabharwal</a>, 
<a href="https://allenai.org/team/peterc" style="text-decoration:none">Peter Clark</a>, 
and
<a href="https://allenai.org/team/tushark" style="text-decoration:none">Tushar Khot</a>.
Preprint.
-->
